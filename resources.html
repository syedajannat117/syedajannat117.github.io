<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="google-site-verification" content="kub8y40iDtj6bks9hWvYjOmMcs7OHwck54UGn3uUMCQ" />
    <meta name="author" content="Ismail Hossain">
    <META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">
    <meta name="description" content="#" />
    <meta property="og:title" content="About | Ismail Hossain">
    <meta property="og:image" content="images/profile2.jpg">
    <meta property="og:description" content="#">
    <title>Publication | Ismail Hossain</title>

    <!-- Bootstrap 4 CSS. This is for the alpha 3 release of Bootstrap 4. This should be updated when Bootstrap 4 is officially released. -->
    <!-- <link rel="stylesheet" href="css/bootstrap.min.css"> -->

    <!-- Custom CSS: You can use this stylesheet to override any Bootstrap styles and/or apply your own styles -->
    <link href="css/style.css" rel="stylesheet">

    <!-- For icons -->


    <!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
      integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"> -->

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css" />

    <script src='https://kit.fontawesome.com/a076d05399.js' crossorigin='anonymous'></script>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css">
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.4/dist/jquery.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>

    <style>
        #more {
            display: none;
        }

        .icons-row {
            display: inline-block;
            vertical-align: top;
        }

        .text-color {
            color: rgb(255, 255, 255);
        }

        .card-publication {
            flex-direction: row;
            align-items: center;
            font-size: 12px;
        }
    </style>
</head>

<body>
    <!-- Navigation -->
    <nav class="navbar sticky-top navbar-expand-md navbar-dark" style="background: rgb(138, 8, 8);">
        <a class="navbar-brand" href="#"><span>
                <img src="images/logo.png" /></span></a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#collapsibleNavbar">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="collapsibleNavbar">
            <ul class="navbar-nav">
                <li class="nav-item">
                    <a class="nav-link" href="index.html">Home</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link text-color" href="publication.html">Publications</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link text-color"
                        href="https://www2.cs.siu.edu/~stalukder/supremelab/index.html">Research
                        Lab</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link text-color" href="education.html">Education</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link text-color" href="achievements.html">Achievements</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link text-color" href="about.html">About</a>
                </li>
                <li><a class="nav-link text-color" href="blog.html">Blog</a></li>
                <li><a class="nav-link text-color" href="gallery.html">Gallery</a></li>
            </ul>
        </div>
    </nav>
    <br>
    <div class="container-fluid">
        <div class="row">
            <!-- Left Column -->
            <div class="col-md-3">

                <div class="card">
                    <img src="images/profile2.jpg" class="rounded-circle shadow-4-strong mx-auto profile-img"
                        alt="Cinque Terre">
                    <!-- <img src="images/profile2.jpg" class="card-img-top" alt="..."> -->
                    <div class="card-body">
                        <h5 class="card-title" style="text-align: center;">Ismail Hossain</h5>
                        <div class="card-text" style="text-align: center;">
                            <b>Ph.D Student</b>
                            <br><b>Researcher Assistant</b>, <a
                                href="https://www2.cs.siu.edu/~stalukder/supremelab/index.html"><b>S</b>ec<b>u</b>rity
                                and
                                <b>Pr</b>ivacy <b>E</b>nhanced <b>M</b>achine L<b>e</b>arning (SUPREME) Lab</a>
                            <!-- <br>Engineering A321, School of Computing
                 <br>Southern Illinois University
                 <br><i class="fa fa-phone" aria-hidden="true"></i> (773) 355-9699 -->
                            <br>
                            <br><i class="fa fa-envelope" aria-hidden="true"></i> <a
                                href="https://www2.cs.siu.edu/~stalukder/mailto:ismail.hossain@siu.edu">ismail.hossain@siu.edu</a>
                            <br><i class="fa fa-file" aria-hidden="true"></i> <a href="CV_Ismail_Hossain.pdf">Curriculum
                                Vitae</a>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-sm-12 text-center">
                            <a href="https://scholar.google.com/citations?user=FexryyIAAAAJ&hl=en"><i
                                    class="fa fa-graduation-cap"></i></a>
                            <!--<li><a href="#"><i class="fab fa-fw fa-orcid"></i> ORCID</a></li>-->
                            <a class="icons-row" href="https://github.com/ismail102"><i class="bi bi-github"></i></a>
                            <a class="icons-row" href="https://www.researchgate.net/profile/Ismail-Hossain-50"><i
                                    class="fa fa-researchgate" aria-hidden="true"></i></a>
                            <!--<li><a href="https://dblp.org/pid/203/0239.html"><i class="fas fa-fw fa-graduation-cap"></i> DBLP</a></li> -->
                            <!--<li><a href="https://twitter.com/IsmailHMukul"><i class="fab fa-fw fa-twitter-square"
                             aria-hidden="true"></i> Twitter</a></li>-->
                            <a class="icons-row" href="https://www.linkedin.com/in/ismail-hossain-90771716a/"><i
                                    class="bi bi-linkedin"></i></a>
                        </div>
                    </div>
                </div>
                <br />
                <div class="card border-success mb-3">
                    <div class="card-header">
                        <h5 class="card-title"><i class="fa fa-cog" aria-hidden="true"></i> Witty Quote</h5>
                    </div>
                    <div class="card-body text-success">
                        <p class="card-text">“By far, the greatest danger of Artificial Intelligence is that people
                            conclude
                            too early that they understand it." – Eliezer Yudkowsky</p>
                    </div>
                </div>

            </div><!--/Left Column-->

            <!-- Center Column -->
            <div class="col">
                <div id="main">
                    <div id="cpaper">
                        <div class="contentText">
                            <h6><strong>Resources</strong></h6>
                        </div>
                        <div class="card card-publication">
                            <img class="card-img-top" style="width: 20%;" src="images/resources/pe.png"
                                alt="Card image cap">
                            <div class="card-body">
                                <h5 class="card-title">Positional Encoding
                                </h5>
                                <p class="card-text">
                                    Positional encoding is used to provide a relative position for each token or word in
                                    a sequence. When reading a sentence, each word is dependent on the words around it.
                                    For instance, some words have different meanings in different contexts, so a model
                                    should be able to understand these variations and the words that each relies on for
                                    context.
                                </p>
                                <p style="font-size: small; color: rgb(132, 132, 149);">
                                    May 8, 2023</p>
                                <did class="d-flex justify-content-between">
                                    <div>
                                        <a class="btn btn-primary btn-sm"
                                            href="https://medium.com/@hunter-j-phillips/positional-encoding-7a93db4109e6"
                                            role="button" aria-expanded="false" aria-controls="bib0">Read More</a>
                                    </div>
                                    <div>
                                        <!-- <span class="badge badge-primary">Transformer</span> -->
                                        <!-- <span class="badge badge-secondary">Secondary</span> -->
                                        <span class="badge badge-success">Transformer</span>
                                        <span class="badge badge-danger">Embedding</span>
                                        <!-- <span class="badge badge-warning">Warning</span>
                                        <span class="badge badge-info">Info</span>
                                        <span class="badge badge-light">Light</span> -->
                                        <span class="badge badge-dark">Medium</span>
                                    </div>
                                </did>
                            </div>
                        </div>
                        <br />
                        <div class="card card-publication">
                            <img class="card-img-top" style="width: 20%;" src="images/resources/pe1.png"
                                alt="Card image cap">
                            <div class="card-body">
                                <h5 class="card-title">
                                    Transformer’s Positional Encoding <br />
                                    <small> How Does It Know Word Positions Without Recurrence? </small>
                                </h5>
                                <p class="card-text">
                                    In 2017, Vaswani et al. published a paper titled Attention Is All You Need for the
                                    NeurIPS conference. They introduced the original transformer architecture for
                                    machine translation, performing better and faster than RNN encoder-decoder models,
                                    which were mainstream at that time.

                                    Then, the big transformer model achieved SOTA (state-of-the-art) performance on NLP
                                    tasks.
                                </p>
                                <p style="font-size: small; color: rgb(132, 132, 149);">
                                    October 30, 2021</p>
                                <did class="d-flex justify-content-between">
                                    <div>
                                        <a class="btn btn-primary btn-sm"
                                            href="https://kikaben.com/transformers-positional-encoding/#post-title"
                                            role="button" aria-expanded="false" aria-controls="bib0">Read More</a>
                                    </div>
                                    <div>
                                        <!-- <span class="badge badge-primary">Transformer</span> -->
                                        <!-- <span class="badge badge-secondary">Secondary</span> -->
                                        <span class="badge badge-success">Transformer</span>
                                        <!-- <span class="badge badge-danger">Danger</span> -->
                                        <!-- <span class="badge badge-warning">Warning</span> -->
                                        <span class="badge badge-info">Machine Translation</span>
                                        <!-- <span class="badge badge-light">Light</span> -->
                                        <span class="badge badge-primary">KiKaBeN</span>
                                    </div>
                                </did>
                            </div>
                        </div>
                        <br />
                        <div class="card card-publication">
                            <img class="card-img-top" style="width: 20%;" src="images/resources/pe2.png"
                                alt="Card image cap">
                            <div class="card-body">
                                <h5 class="card-title">
                                    Transformer Architecture: The Positional Encoding
                                    <br />
                                    <small> Let's use sinusoidal functions to inject the order of words in our model
                                    </small>
                                </h5>
                                <p class="card-text">
                                    Transformer architecture was introduced as a novel pure attention-only
                                    sequence-to-sequence architecture by Vaswani et al. Its ability for parallelizable
                                    training and its general performance improvement made it a popular option among NLP
                                    (and recently CV) researchers.
                                </p>
                                <p style="font-size: small; color: rgb(132, 132, 149);">
                                    September 20, 2019</p>
                                <did class="d-flex justify-content-between">
                                    <div>
                                        <a class="btn btn-primary btn-sm"
                                            href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/"
                                            role="button" aria-expanded="false" aria-controls="bib0">Read More</a>
                                    </div>
                                    <div>
                                        <!-- <span class="badge badge-primary">Transformer</span> -->
                                        <!-- <span class="badge badge-secondary">Secondary</span> -->
                                        <span class="badge badge-success">Transformer</span>
                                        <!-- <span class="badge badge-danger">Danger</span> -->
                                        <span class="badge badge-warning">Sinusoidal </span>
                                        <!-- <span class="badge badge-info">Machine Translation</span> -->
                                        <!-- <span class="badge badge-light">Light</span> -->
                                        <span class="badge badge-primary">kazemnejad</span>
                                    </div>
                                </did>
                            </div>
                        </div>
                        <br />
                        <div class="card card-publication">
                            <img class="card-img-top" style="width: 20%;" src="images/resources/bs.png"
                                alt="Card image cap">
                            <div class="card-body">
                                <h5 class="card-title">
                                    BEAM Search
                                </h5>
                                <p class="card-text">
                                    BEAM Search, a variant of breadth-first Search, is an algorithm that searches a
                                    weighted graph for an optimal path from some start node S to some goal node G. The
                                    difference between BEAM search and breadth-first search is that at every level of
                                    the search tree, only the top β candidates are chosen for further exploration. Here,
                                    β is known as the beam width. The reasoning behind this is that a path from S to G
                                    is likely to pass through some top number of most promising nodes.
                                </p>
                                <p style="font-size: small; color: rgb(132, 132, 149);">
                                    Jun 5, 2023</p>
                                <did class="d-flex justify-content-between">
                                    <div>
                                        <a class="btn btn-primary btn-sm"
                                            href="https://www.codecademy.com/resources/docs/ai/search-algorithms/beam-search"
                                            role="button" aria-expanded="false" aria-controls="bib0">Read More</a>
                                    </div>
                                    <div>
                                        <!-- <span class="badge badge-primary">Transformer</span> -->
                                        <!-- <span class="badge badge-secondary">Secondary</span> -->
                                        <span class="badge badge-success">Beam Search</span>
                                        <!-- <span class="badge badge-danger">Danger</span> -->
                                        <span class="badge badge-warning">NLP</span>
                                        <!-- <span class="badge badge-info">Machine Translation</span> -->
                                        <!-- <span class="badge badge-light">Light</span> -->
                                        <span class="badge badge-primary">Codecademy</span>
                                    </div>
                                </did>
                            </div>
                        </div>
                        <br />
                        <div class="card card-publication">
                            <img class="card-img-top" style="width: 20%;" src="images/resources/bs1.png"
                                alt="Card image cap">
                            <div class="card-body">
                                <h5 class="card-title">
                                    Foundations of NLP Explained Visually: Beam Search, How It Works
                                </h5>
                                <p class="card-text">
                                    Many NLP applications such as machine translation, chatbots, text summarization, and
                                    language models generate some text as their output. In addition applications like
                                    image captioning or automatic speech recognition (ie. Speech-to-Text) output text,
                                    even though they may not be considered pure NLP applications.
                                </p>
                                <p style="font-size: small; color: rgb(132, 132, 149);">
                                    April 1, 2021</p>
                                <did class="d-flex justify-content-between">
                                    <div>
                                        <a class="btn btn-primary btn-sm"
                                            href="https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24"
                                            role="button" aria-expanded="false" aria-controls="bib0">Read More</a>
                                    </div>
                                    <div>
                                        <!-- <span class="badge badge-primary">Transformer</span> -->
                                        <!-- <span class="badge badge-secondary">Secondary</span> -->
                                        <span class="badge badge-success">Beam Search</span>
                                        <!-- <span class="badge badge-danger">Danger</span> -->
                                        <span class="badge badge-warning">NLP</span>
                                        <!-- <span class="badge badge-info">Machine Translation</span> -->
                                        <!-- <span class="badge badge-light">Light</span> -->
                                        <span class="badge badge-primary">Towardsdatascience</span>
                                    </div>
                                </did>
                            </div>
                        </div>
                        <br />
                        <div class="card card-publication">
                            <img class="card-img-top" style="width: 20%;" src="images/resources/bs1.png"
                                alt="Card image cap">
                            <div class="card-body">
                                <h5 class="card-title">
                                    Unmasking BERT: The Key to Transformer Model Performance
                                </h5>
                                <p class="card-text">
                                    It seems clear that at the moment, practice is far ahead of theory in the
                                    technological life cycle of Deep Learning for NLP. We’re using approaches like
                                    masking which seem to work, and we fiddle with the numbers a bit and it works a
                                    little better or a little worse. Yet we can’t fully explain why that happens!

                                    Some people may find this frustrating and disappointing. If we can’t explain it,
                                    then how can we use it?
                                </p>
                                <p style="font-size: small; color: rgb(132, 132, 149);">
                                    August 18, 2023</p>
                                <did class="d-flex justify-content-between">
                                    <div>
                                        <a class="btn btn-primary btn-sm"
                                            href="https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24"
                                            role="button" aria-expanded="false" aria-controls="bib0">Read More</a>
                                    </div>
                                    <div>
                                        <span class="badge badge-primary">BERT</span>
                                        <!-- <span class="badge badge-secondary">Secondary</span> -->
                                        <!-- <span class="badge badge-success">Beam Search</span> -->
                                        <span class="badge badge-danger">Masking</span>
                                        <span class="badge badge-warning">NLP</span>
                                        <!-- <span class="badge badge-info">BERT</span> -->
                                        <!-- <span class="badge badge-light">Masking</span> -->
                                        <span class="badge badge-info">neptune.ai</span>
                                    </div>
                            </div>
                        </div>
                        <br />
                        <div class="card card-publication">
                            <img class="card-img-top" style="width: 20%;"
                                src="images/resources/lora.png" alt="Card image cap">
                            <div class="card-body">
                                <h5 class="card-title">
                                    In-depth Understanding of LoRa and Finetuning a LLM using LoRa
                                </h5>
                                <p class="card-text">
                                    With all the latest innovations in the field of AI, it has
                                    definitely become easy to find solutions to many NLP problems. The
                                    concept of finetuning comes into picture only when you have
                                    questions about your custom data which the pretrained LLM has not
                                    seen and none of the typical prompt engineering techniques are
                                    giving you the expected results.
                                </p>
                                <p style="font-size: small; color: rgb(132, 132, 149);">
                                    August 25, 2023</p>
                                <did class="d-flex justify-content-between">
                                    <div>
                                        <a class="btn btn-primary btn-sm"
                                            href="https://levelup.gitconnected.com/in-depth-understanding-of-lora-and-finetuning-a-llm-using-lora-266aaa991fcd"
                                            role="button" aria-expanded="false"
                                            aria-controls="bib0">Read More</a>
                                    </div>
                                    <div>
                                        <span class="badge badge-primary">LoRa</span>
                                        <span class="badge badge-secondary">LLM</span>
                                        <span class="badge badge-success">Prompt Tuning</span>
                                        <span class="badge badge-danger">SVD</span>
                                        <span class="badge badge-warning">NLP</span>
                                        <!-- <span class="badge badge-info">Machine Translation</span> -->
                                        <!-- <span class="badge badge-light">Light</span> -->
                                        <span class="badge badge-primary">Levelup</span>
                                    </div>
                                </did>
                            </div>
                        </div>
                        <br />
                    </div>
                </div>

            </div><!--/container-fluid-->
        </div>
    </div>

    <footer class="footer mt-auto py-3" style="background: rgb(138, 8, 8);">
        <div class="container">
            <span class="text-light">
                <p>&copy; 2024 All Rights Reserve to Ismail Hossain </p>
            </span>
        </div>
    </footer>

</body>

</html>